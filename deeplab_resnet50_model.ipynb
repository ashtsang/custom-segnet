{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a329dcb7",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labuser\\.conda\\envs\\custom_segnet\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, time, copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d6519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  True\n"
     ]
    }
   ],
   "source": [
    "## define global variables\n",
    "VERSION = 1.0\n",
    "\n",
    "INPUT_SIZE = 512\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 7\n",
    "MODEL_SAVE_NAME = 'deeplab_resnet50_model_50'\n",
    "\n",
    "print(\"Using GPU: \", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29160594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, inputs: list, targets: list, transform=None):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.inputs_dtype = torch.float32\n",
    "        self.targets_dtype = torch.long\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # Select the sample\n",
    "        input_ID = self.inputs[index]\n",
    "        target_ID = self.targets[index]\n",
    "\n",
    "        # Load input and target\n",
    "        x = cv2.imread(input_ID) / 255\n",
    "        y = cv2.imread(target_ID, cv2.IMREAD_UNCHANGED) # to read tif image, y is NHW\n",
    "        \n",
    "        x = np.moveaxis(x, -1, 0) # modify x from NHWC to NCHW\n",
    "\n",
    "        # Preprocessing - should already be done in previous step, make sure to load in pre-processed data\n",
    "        if self.transform is not None:\n",
    "            x, y = self.transform(x, y)\n",
    "\n",
    "        # Typecasting\n",
    "        x, y = torch.from_numpy(x).type(self.inputs_dtype), torch.from_numpy(y).type(self.targets_dtype)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bcdba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im_dir = r'\\\\babyserverdw5\\Digital pathology image lib\\JHU\\Ie-Ming Shih\\lymphocytes\\230110 dataset\\{}x{}_v{}\\train\\images'.format(INPUT_SIZE, INPUT_SIZE,VERSION)\n",
    "train_ann_dir = r'\\\\babyserverdw5\\Digital pathology image lib\\JHU\\Ie-Ming Shih\\lymphocytes\\230110 dataset\\{}x{}_v{}\\train\\labels'.format(INPUT_SIZE, INPUT_SIZE, VERSION)\n",
    "\n",
    "train_im_list = [os.path.join(train_im_dir, f) for f in os.listdir(train_im_dir) if f[-3:] != '.db']\n",
    "train_ann_list = [os.path.join(train_ann_dir, f) for f in os.listdir(train_ann_dir)]\n",
    "\n",
    "val_im_dir = r'\\\\babyserverdw5\\Digital pathology image lib\\JHU\\Ie-Ming Shih\\lymphocytes\\230110 dataset\\{}x{}_v{}\\val\\images'.format(INPUT_SIZE, INPUT_SIZE,VERSION)\n",
    "val_ann_dir = r'\\\\babyserverdw5\\Digital pathology image lib\\JHU\\Ie-Ming Shih\\lymphocytes\\230110 dataset\\{}x{}_v{}\\val\\labels'.format(INPUT_SIZE, INPUT_SIZE, VERSION)\n",
    "\n",
    "val_im_list = [os.path.join(val_im_dir, f) for f in os.listdir(val_im_dir) if f[-3:] != '.db']\n",
    "val_ann_list = [os.path.join(val_ann_dir, f) for f in os.listdir(val_ann_dir)]\n",
    "\n",
    "# train_im_list = [f for f in im_list if f[-5:] != '0.tif']\n",
    "# train_ann_list = [f for f in ann_list if f[-5:] != '0.tif']\n",
    "\n",
    "# val_im_list = [f for f in im_list if f[-5:] == '0.tif']\n",
    "# val_ann_list = [f for f in ann_list if f[-5:] == '0.tif']\n",
    "\n",
    "train_dataset = CustomDataset(inputs=train_im_list, targets=train_ann_list, transform=None)\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(inputs=val_im_list, targets=val_ann_list, transform=None)\n",
    "val_dataloader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c9a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## train samples ##\n",
      "x = shape: torch.Size([7, 3, 512, 512]); type: torch.float32\n",
      "x = min: 0.027450980618596077; max: 1.0\n",
      "y = shape: torch.Size([7, 512, 512]); class: tensor([0, 4, 5, 9]); type: torch.int64\n",
      "num samples: 3600\n",
      "## val samples ##\n",
      "x = shape: torch.Size([7, 3, 512, 512]); type: torch.float32\n",
      "x = min: 0.0117647061124444; max: 1.0\n",
      "y = shape: torch.Size([7, 512, 512]); class: tensor([0, 1, 2, 4, 5, 8, 9]); type: torch.int64\n",
      "num samples: 1200\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_dataloader))\n",
    "print('## train samples ##')\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')\n",
    "print(f'num samples: {len(train_dataset)}')\n",
    "\n",
    "x, y = next(iter(val_dataloader))\n",
    "print('## val samples ##')\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')\n",
    "print(f'num samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3384a7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.segmentation.deeplabv3_resnet50('COCO_WITH_VOC_LABELS_V1')\n",
    "model.classifier[4] = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "model.aux_classifier[4] = torch.nn.Conv2d(256, NUM_CLASSES, kernel_size=(1, 1), stride=(1, 1))\n",
    "# for p in model.backbone.parameters():\n",
    "#     p.requires_grad = False\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c8402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/515\r"
     ]
    }
   ],
   "source": [
    "# get class weighting of entire dataset\n",
    "def get_total_class_weights():\n",
    "    class_counts = np.zeros(NUM_CLASSES)\n",
    "    for ii, (inputs, labels) in enumerate(train_dataloader):\n",
    "        this_class_types, this_class_counts = np.unique(labels, return_counts=True) # returns tuple of (class_types, class_counts)\n",
    "        for cls, cnt in zip(this_class_types, this_class_counts):\n",
    "            class_counts[cls] += cnt\n",
    "        print('{}/{}'.format(ii, len(train_dataloader)), end='\\r')\n",
    "    return class_counts\n",
    "\n",
    "class_counts = get_total_class_weights()\n",
    "print('Class counts:', class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_part = class_counts[:-1]\n",
    "\n",
    "CLASS_WEIGHTS = class_counts_part.sum() / (class_counts_part.shape[0] * class_counts_part)\n",
    "CLASS_WEIGHTS = np.concatenate((CLASS_WEIGHTS, np.zeros(1)),0)\n",
    "\n",
    "CLASS_WEIGHTS = np.clip(CLASS_WEIGHTS, 0, 2000)\n",
    "\n",
    "for ii, (c, w) in enumerate(zip(class_counts, CLASS_WEIGHTS)):\n",
    "    print(f'cls {ii} | cnt {str(int(c)):12s} | weight {str(w):12s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09795598",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CLASS_WEIGHTS)\n",
    "def get_acc(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for ii, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)['out']\n",
    "            pred = torch.argmax(outputs, 1)\n",
    "        \n",
    "        gt_ind = torch.logical_and(labels > 0, labels < NUM_CLASSES-1)\n",
    "        t = gt_ind.sum().item()\n",
    "        \n",
    "        if t > 0:\n",
    "            c = torch.sum(pred[gt_ind] == labels[gt_ind]).item()\n",
    "            correct += c\n",
    "            total += t\n",
    "        \n",
    "    return correct / total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, num_classes):\n",
    "    \n",
    "    model_save_dir = r'\\\\babyserverdw3\\PW Cloud Exp Documents\\Lab work documenting\\W-22-09-10 AT Build Competent multi task DL model for tissue labeling/saved_models/230110/{}x{}_v{}'.format(INPUT_SIZE, INPUT_SIZE,VERSION)\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.mkdir(model_save_dir)\n",
    "    path_to_saved_model = os.path.join(model_save_dir,'{}.tar'.format(MODEL_SAVE_NAME))\n",
    "    print('saving model to: ', path_to_saved_model)\n",
    "            \n",
    "    model.train()\n",
    "    best_acc = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loader, val_loader = dataloaders\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        running_avg_loss = 0\n",
    "        \n",
    "        for ii, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels_copy = labels\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "\n",
    "            outputs = model(inputs)['out']  \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_avg_loss = running_avg_loss * (ii/(ii+1)) + loss.item() * (1/(ii+1))\n",
    "            \n",
    "            if ii % 25 == 0:\n",
    "                print(f'E{epoch}B{ii} | loss: {loss.item():.3f} ({running_avg_loss:.3f})')\n",
    "        \n",
    "        model.eval()\n",
    "        val_acc = get_acc(model, val_loader)\n",
    "        model.train()\n",
    "        \n",
    "        done = (epoch + 1) / num_epochs\n",
    "        left = 1 - done\n",
    "        eta = (time.time() - start) / done * left / 60\n",
    "        \n",
    "        print(f'Epoch {epoch}/{num_epochs} | loss: {running_avg_loss:.3f} | acc: {val_acc:.3f} | ETA: {eta:.2f} min')\n",
    "        if val_acc > best_acc:\n",
    "            print(\"===== Best validation performance - saving best model =====\")\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), path_to_saved_model)\n",
    "            \n",
    "        print()\n",
    "        scheduler.step()\n",
    "\n",
    "# just save the last model too\n",
    "last_path_to_saved_model = os.path.join(model_save_dir,'{}_last.tar'.format(MODEL_SAVE_NAME))\n",
    "torch.save(model.state_dict(), last_path_to_saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceaeaca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloaders = [train_dataloader, val_dataloader]\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(CLASS_WEIGHTS).float()).to(device)\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "model = train_model(model, dataloaders, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=50, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(os.path.join(r'\\\\babyserverdw3\\PW Cloud Exp Documents\\Lab work documenting\\W-22-09-10 AT Build Competent multi task DL model for tissue labeling/saved_models/230110/{}x{}_v{}'.format(INPUT_SIZE, INPUT_SIZE,VERSION), '{}.tar'.format(MODEL_SAVE_NAME)))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print('===== Trained Model Summary =====')\n",
    "print('Train Accuracy:      {:.3f}%'.format(100*get_acc(model, train_dataloader)))\n",
    "print('Validation Accuracy: {:.3f}%'.format(100*get_acc(model, val_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "\n",
    "import math\n",
    "\n",
    "model.eval()   # Set model to the evaluation mode\n",
    "\n",
    "# Get the first batch\n",
    "inputs, labels = next(iter(train_dataloader))\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)\n",
    "print('inputs.shape', inputs.shape)\n",
    "print('labels.shape', labels.shape)\n",
    "\n",
    "# Predict\n",
    "pred = model(inputs)['out']\n",
    "# The loss functions include the sigmoid function.\n",
    "pred = pred.data.cpu().numpy()\n",
    "print('pred.shape', pred.shape)\n",
    "pred = np.argmax(pred, 1)\n",
    "print('pred.shape', pred.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('true')\n",
    "true = labels.data.cpu().numpy()\n",
    "plt.imshow(true[0])\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('pred')\n",
    "plt.imshow(pred[0])\n",
    "print(np.unique(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a236eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
